# -*- coding: utf-8 -*-
"""Visualizing Word Vectors

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Aq0CJdsFgBB-WIlnMekONrXEmurbpWIV

# Visualizing Word Vectors with t-SNE

TSNE is pretty useful when it comes to visualizing similarity between objects. It works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words.

### Steps

1. Clean the data
2. Build a corpus
3. Train a Word2Vec Model
4. Visualize t-SNE representations of the most common words

Credit: Some of the code was inspired by this awesome [NLP repo][1].




  [1]: https://github.com/rouseguy/DeepLearningNLP_Py
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
pd.options.mode.chained_assignment = None
import numpy as np
import re
import nltk
nltk.download("stopwords")

from gensim.models import word2vec

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
# %matplotlib inline

url='https://drive.google.com/file/d/1DNi7Uex2RUfTWcyVJqY6d6Tp7GJaeSUl/view'
url='https://drive.google.com/uc?id=' + url.split('/')[-2]


data = pd.read_csv(url)#.sample(50000, random_state=23)
data.head()

import gspread as gs

#https://docs.google.com/spreadsheets/d/1Fp1T2Q1K-DVElVS-ta_QgqKj27y5wP88oC5p1O9gypA/edit?usp=sharing
#get spreadsheets key from url
gsheetkey = "1Fp1T2Q1K-DVElVS-ta_QgqKj27y5wP88oC5p1O9gypA"

#sheet name
sheet_name = 'Data Baru'

url=f'https://docs.google.com/spreadsheet/ccc?key={gsheetkey}&output=xlsx'
df = pd.read_excel(url,sheet_name=sheet_name)
df

STOP_WORDS = nltk.corpus.stopwords.words()

def clean_sentence(val):
    "remove chars that are not letters or numbers, downcase, then remove stop words"
    regex = re.compile('([^\s\w]|_)+')
    sentence = regex.sub('', val).lower()
    sentence = sentence.split(" ")

    for word in list(sentence):
        if word in STOP_WORDS:
            sentence.remove(word)

    sentence = " ".join(sentence)
    return sentence

def clean_dataframe(data):
    "drop nans, then apply 'clean_sentence' function to Rescue Story"
    data = data.dropna(how="any")

    for col in ['Rescue Story']:
        data[col] = data[col].apply(clean_sentence)

    return data

data = clean_dataframe(df)
data.info()

def build_corpus(data):
    "Creates a list of lists containing words from each sentence"
    corpus = []

    for col in data['Rescue Story']:
      corpus.append(col.split(" "))
      # for word in col.split(" "):
        # temp.append(word)

      # corpus.append(temp)

    return corpus

corpus = build_corpus(data)
corpus[-1]

"""# Word 2 Vec

The Word to Vec model produces a vocabulary, with each word being represented by an n-dimensional numpy array (100 values in this example)
"""

#### next:
## build custom vocab ,
## baru model di fit pake vocabnya (jangan pake corpus?)

model = word2vec.Word2Vec(corpus, vector_size=100, window=20, min_count=5, workers=4)
model.wv['loving']

model.wv.key_to_index

def tsne_plot(model):
    "Creates and TSNE model and plots it"
    labels = []
    tokens = []

    for word in model.wv.key_to_index:
        tokens.append(model.wv.get_vector(word))
        labels.append(word)
    print(tokens)

    tsne_model = TSNE(perplexity=5, n_components=2, init='pca', n_iter=2500, random_state=23)
    tokens_array = np.array(tokens)
    new_values = tsne_model.fit_transform(tokens_array)

    x = []
    y = []
    for value in new_values:
        x.append(value[0])
        y.append(value[1])

    plt.figure(figsize=(16, 16))
    for i in range(len(x)):
        print(x[i], y[i])
        plt.scatter(x[i],y[i])
        plt.annotate(labels[i],
                     xy=(x[i], y[i]),
                     xytext=(5, 2),
                     textcoords='offset points',
                     ha='right',
                     va='bottom')
    plt.show()

tsne_plot(model)

# A more selective model
model = word2vec.Word2Vec(corpus, vector_size=100, window=20, min_count=10, workers=4)
tsne_plot(model)

# A less selective model
model = word2vec.Word2Vec(corpus, vector_size=100, window=20, min_count=3, workers=4)
tsne_plot(model)

"""# It's Becoming Hard to Read

With a dataset this large, its difficult to make an easy-to-read TSNE visualization. What you can do is use the model to look up the most similar words from any given point.
"""

model.wv.most_similar('nature')

model.wv.most_similar('lunas')

"""# The End

Good luck!
"""